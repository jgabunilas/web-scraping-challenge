{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping Challenege\n",
    "## Written by Jason Gabunilas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import splinter, BeautifulSoup, Requests, Pandas\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the NASA Mars News Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "\n",
    "\n",
    "# Chromedriver executable path\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "browser.visit(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the latest news item, which is the first instance of the div of class \"list_text\". Then search within the news_item\n",
    "latest_news_item = soup.find('div', class_=\"list_text\")\n",
    "news_title = latest_news_item.find('div', class_=\"content_title\").text\n",
    "news_paragraph = latest_news_item.find('div', class_=\"article_teaser_body\").text\n",
    "# print(news_title)\n",
    "# print(news_paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the JPL Mars images website and open with splinter\n",
    "url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "browser.visit(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soupify the browser\n",
    "time.sleep(5)\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA19168-1920x1200.jpg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The featured image URL lies within an article tag under a style attribute. However, this soup find will return a partial URL that has unneeded information. This extraneous information will need to be sliced out of the string. Regardless of how long the URL is, we can get at the part that we care about by slicing from the 23rd character to the third-to-last character.\n",
    "featured_image = soup.find('article')['style']\n",
    "# featured_image[23:-3]\n",
    "\n",
    "# The featured image URL can be completed by adding the featured_image slice to the base URL.\n",
    "featured_image_url = f'https://www.jpl.nasa.gov' + featured_image[23:-3]\n",
    "# featured_image_url\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set url for Mars Facts\n",
    "url = 'https://space-facts.com/mars/'\n",
    "mars_facts = pd.read_html(url)\n",
    "# Convert to a dataframe\n",
    "mars_facts_df = mars_facts[0]\n",
    "# Update Column Names\n",
    "mars_facts_df = mars_facts_df.rename(columns = {0:'Property', 1:'Value'})\n",
    "mars_facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframe to HTML, removing the index labels\n",
    "mars_facts_html = mars_facts_df.to_html(index=False)\n",
    "print(mars_facts_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initiate an empty list for the title and img_url dictionaries\n",
    "hemisphere_image_urls = []\n",
    "urls = [\n",
    "    'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced',\n",
    "    'https://astrogeology.usgs.gov/search/map/Mars/Viking/cerberus_enhanced',\n",
    "    'https://astrogeology.usgs.gov/search/map/Mars/Viking/schiaparelli_enhanced',\n",
    "    'https://astrogeology.usgs.gov/search/map/Mars/Viking/syrtis_major_enhanced'\n",
    "]\n",
    "\n",
    "# Scrape the image URLs using a for loop to iterate though each respective page and dig up the image URL for the hemisphere and the title of the hemisphere\n",
    "for url in urls:\n",
    "    executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    browser.visit(url)\n",
    "\n",
    "    time.sleep(5)\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    title = soup.find('h2', class_='title').text\n",
    "    img_url = 'https://astrogeology.usgs.gov'+soup.find('img', class_='wide-image')['src']\n",
    "    print(title)\n",
    "    print(img_url)\n",
    "\n",
    "    # Append the scraped title and image url to the hemisphere_image_urls dictionary\n",
    "    hemisphere_image_urls.append(\n",
    "        {\n",
    "            'title': title,\n",
    "            'img_url': img_url\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
